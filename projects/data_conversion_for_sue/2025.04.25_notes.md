Chatting with Saskia about the approach for generating metadata here:
* for metadata, approach each of the 5 categories one at a time
* rig is going to very different, give it a name (e.g. sue_ephys_rig_v1), get as much info as possible. 
* Many mice will have procedures in the NSB data. Use endpoint when possible.
* Rigs here at the institute - we should be able to make a rig.json (and maybe it already esists)
* May need to add a new probe type in data schema models devices.ProbeModel class to represent tetrodes
* don't worry about angles in ephys session. 
* In session, get as much stimulus epoch info as possible from data files. 
* I need to check with David on data organization. Sue currently has a data organization that combines raw and processed data. How do we handle this? This is relevant to old Hopkins data, not data being actively collected. 

## Subject ID Mapping (June 17, 2025)

Sue provided mapping between old Hopkins subject IDs and new AIND subject IDs:

KJ_23_016 (KJ005) → 669489
KJ_23_017 (KJ006) → 669491  
KJ_23_018 (KJ007) → 669492
KJ_23_026 (KJ008) → 672368
KJ_23_028 (KJ009) → 672850
KJ_23_043 (KJ010) → 676879
KJ_23_044 (KJ011) → 678084
KJ_23_045 (KJ012) → 678085

This mapping has been implemented in `get_procedures_and_subject_metadata.py` so we can now fetch subject and procedure metadata for the Hopkins subjects through the metadata service.

## 6/17 meeting with Saskia
* I need injection materials for all procedures. Need full name of virus from Sue. Ideally with addgene ID. Titer also. 
* I need targeted structure for the injections from Sue. this is optional but would be ideal to add. This is for both the injections and the fiber probes. (probably the same for all)
* for tags in data descriptions: make empty for now
* make sure to note in acquisition that time is approximated (assumed to be noon)
* get orcids for jeremiah and sue
* funding and investigator should come from project

## 7/1 meeting with Saskia:
* for data description:
    * creation time should be local time with offset, not "Z" format
* acquisition_type: string should be informative. If there are different variants of the DF task, this should be here. If it's training, include that here. Sue should be able to fill this in EG. This is the searchable field for identifying similar chunks of data in a dataset.
* for each data stream, we need:
    * start and end time. 
    * List of modalities
    * data streams can be grouped for modalities that have similar start/end times
    * list of active devices (e.g. eye tracking camera, body camera, ephys_probe_name (if ephys))
    * for each fiber_photometry experiment, we need patch coord config, which is a list of channels. Each channel needs:
        * name
        * intended_measurement
        * detector_config (exposure time, trigger type, )
        * additional device names (optional)
        * light_source_config (wavelength if laser, power)
        * excitation filters (optional)
        * emission filters (optional)
        * emission wavelength (optional)

    * for each ephys experiment, we need:
        * name of ephys probe

* For each stimulus_epoch, we need:
    * start_time
    * end_time
    * stimulus_name
    * code used to run stimulus (ideally URL to code repo)
    * parameters (dictionary of user-defined key params that describe stimulus)
    * List of stimulus modalities ("auditory" for dynamic foraging)
    * performance_metrics 
        * output_parameters (user defined dict)
        * reward_consumed_during_epoch
        * total_number_of_trials
        * trials_finished
        * trials_rewarded
    * notes
    * active_devices (e.g. speaker)
* subject
    * pre weight (optional)
    * post weight (optional)
    * total_reward_consumed (likely same as epoch if only one epoch)
    * mouse_platform_name ()